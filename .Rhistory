#bw - this is the bandwidth parameter for the kernel density estimation of the circular angular density. Should be a positive number. Defaults to 50
if(!is.matrix(sample_data) | ncol(sample_data) != 2){
stop("sample_data must be an n x 2 matrix, where n denotes number of observations")
}
if(nsim < 1 | length(nsim) != 1){
stop("nsim must be a positive real integer")
}
if(!(norm_choice %in% c("L1","L2"))){
stop("norm_choice must equal either 'L1' or 'L2'")
}
if(thresh_prob >= 1 | thresh_prob <= 0 | length(thresh_prob) != 1){
stop("thresh_prob must be a single probability in (0,1)")
}
if(round(k) != k | k<=3){
stop("k must be a natural number greater that 3")
}
if(!is.null(k_shape)){
if(round(k_shape) != k_shape | k_shape<=3){
stop("If not set to NULL (i.e., constant shape), k_shape must be a natural number greater that 3")
}
}
if(min(pred_Q) < -2 | max(pred_Q)>2 | length(pred_Q)<=1){
stop("pred_Q should be a grid of angles in the interval [-2,2]")
}
if(bw < 0 | length(bw) != 1){
stop("bw must be a positive real number")
}
#We first transform data to radial-angular coordinates
#All radial/angular/sgn functions are repeated inside this function. This allows for easier parallelisation of the code
sgn = function(y){
if(y>=0){
return(1)
} else {
return(-1)
}
}
if(norm_choice == "L1"){
L1_rad = function(vec){
return(abs(vec[1])+abs(vec[2]))
}
L1_ang = function(vec){
return(sgn(vec[2])*(1-vec[1]))
}
#observed radial data
R = apply(sample_data,1,L1_rad)
#observed angular data
Q = apply( apply(sample_data,2,function(x,r){return(x/r)},r=R),1,L1_ang)
} else {
L2_rad = function(vec){
return(sqrt(vec[1]^2+vec[2]^2))
}
L2_ang = function(vec){
return(sgn(vec[2])*(2/pi)*acos(vec[1]))
}
#observed radial data
R = apply(sample_data,1,L2_rad)
#observed angular data
Q = apply( apply(sample_data,2,function(x,r){return(x/r)},r=R),1,L2_ang)
}
#dataframe of angular-radial data
polar_data = data.frame(R=R,Q=Q)
#transform radial component to the log scale. This guarantees positivity in the resulting threshold function
polar_data$logR = log(polar_data$R)
#Formulation for threshold function. s(Q, bs='cc',k=k) is a cyclic cubic spline over Q with basis dimension k
fmla_ald = paste0("logR ~ s(Q, bs='cc',k=",k,")")
#Fit asymmetric Laplace distribution to estimate threshold function using evgam
m_ald = evgam(as.formula(fmla_ald), data=polar_data, family="ald", ald.args=list(tau=thresh_prob))
#Estimated threshold functions. The exp function is used to transform back to R from the logR scale
gpd_thresh_function = exp(predict(m_ald, newdata=polar_data)$location)
#all exceedances of threshold function
gpd_thresh_exceedances = polar_data$R - gpd_thresh_function
#checking which exceedances are positive
positive_exceedances_indicator = which(gpd_thresh_exceedances>0)
#extracting positive exceedances
gpd_thresh_exceedances = gpd_thresh_exceedances[positive_exceedances_indicator]
#dataframe of threshold exceedance data. We only save exceedances - we don't need the rest of the radial data
polar_exceedance_data = data.frame(Q=polar_data$Q[positive_exceedances_indicator],R_exc=gpd_thresh_exceedances)
#We now fit the non-stationary generalised Pareto distribution (GPD) using evgam
#Checking if the shape is assumed to be constant
if(is.null(k_shape)){
#formulation for scale function
spl=paste0("R_exc ~ s(Q, bs='cc',k=",k,")")
#formulation for both scale and shape. ~1 specifies a constant shape
fmla_gpd = list(as.formula(spl), ~1)
#fit non-stationary GPD model using evgam
m_gpd = evgam(fmla_gpd, data=polar_exceedance_data, family="gpd")
} else {
#define second angular component that is identical as first. This is so that we can define separate splines for the shape and scale
polar_exceedance_data$Q2 = polar_exceedance_data$Q
#formulation for both scale and shape. Note that k and k_shape are unlikely to be the same
fmla_gpd = list(as.formula(paste0("R_exc ~ s(Q, bs='cc',k=",k,")")), as.formula(paste0("R_exc ~ s(Q2, bs='cc',k=",k_shape,")")))
#fit non-stationary GPD model using evgam
m_gpd = evgam(fmla_gpd, data=polar_exceedance_data, family="gpd")
}
#we transform the angular component to be within the interval [0,2pi). This is because the density.circular function is defined only for standard polar angles
scale_Q = (Q+2)*pi/2
#estimating the density function using the `circular' R package with a von Mises kernel
dens_est = density.circular(as.circular(scale_Q,type="angles",units="radians",template="none",modulo="2pi",zero=0,rotation="counter"), bw=bw,kernel="vonmises")
#Making sure we equal 2pi at the endpoint
dens_est$x[length(dens_est$x)] = 2*pi
#obtaining the estimated density function on the original angular scale. (pi/2) represents the corresponding Jacobian
f_Q = approxfun(x = (2*dens_est$x)/pi - 2,y = (pi/2)*dens_est$y)
kd_integral = function(u,x,f_Q){
if(x>0.99999){
return(1 - u) #numerical error for really large probabilities. This ensures we integrate to 1
} else {
return(integrate(f_Q,-2,x)$value - u)
}
}
kd_root = function(u,f_Q){
return(uniroot(f=kd_integral,interval = c(-2,2),u=u,f_Q = f_Q)$root)
}
unif_sample = runif(nsim)
Q_sample = sapply(unif_sample,kd_root,f_Q=f_Q)
#obtain threshold function estimates for sample angles
thresh_sample = exp(predict(m_ald, newdata=data.frame(Q=Q_sample))$location)
if(is.null(k_shape)){
#obtain GPD parameter function estimates for sample angles
para_sample = predict(m_gpd, newdata=data.frame(Q=Q_sample),type="response")
} else {
#obtain GPD parameter function estimates for sample angles
para_sample = predict(m_gpd,type = "response",newdata=data.frame(Q=Q_sample,Q2=Q_sample))
}
unif_sample = runif(nsim)
R_sample = thresh_sample + (para_sample$scale/para_sample$shape)*(unif_sample^(-para_sample$shape)-1)
#We check which coordinate system we are working in
if(norm_choice == "L1"){
#Defining points on the unit sphere for the L1 norm
u_vec = ifelse(Q_sample>=0,(1-Q_sample),(Q_sample+1))
v_vec = ifelse(Q_sample>=0, 1-abs(u_vec),-1+abs(u_vec))
} else {
#Defining points on the unit sphere for the L2 norm
u_vec = ifelse(Q_sample>=0,cos(pi*Q_sample/2),cos(-pi*Q_sample/2))
v_vec = ifelse(Q_sample>=0, sqrt(1-u_vec^2),-sqrt(1-u_vec^2))
}
data_sample = cbind(R_sample*u_vec,R_sample*v_vec)
#returning simulated datasets
return(list(Q_sample = Q_sample,R_sample = R_sample,data_sample = data_sample))
}
#Simulate new data from fitted SPAR model
SPAR_simulation = SPAR_simulation(sample_data=std_data,nsim=nsim,norm_choice = norm_choice,thresh_prob = thresh_prob,k=k,k_shape = k_shape,pred_Q = pred_Q,bw=bw)
#Plotting estimated equidensity contours
png(file="plots/equidensity_contours.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="Equidensity contours",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(SPAR_equidensity_curves),xlim=range(SPAR_equidensity_curves))
lines(SPAR_equidensity_curves[[1]],lwd=3,col="orange")
lines(SPAR_equidensity_curves[[2]],lwd=3,col="cyan")
legend(range(SPAR_equidensity_curves)[1],range(SPAR_equidensity_curves)[2],legend=c(expression(paste("10"^"-3")),expression(paste("10"^"-6"))),lwd=3,col=2:(length(SPAR_equidensity_curves)+2),cex=1.2,bg="white")
dev.off()
#Plotting estimated return level set
png(file="plots/ret_level_set.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="Return level set estimate",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(SPAR_RL_set),xlim=range(SPAR_RL_set))
lines(SPAR_RL_set,lwd=3,col="purple")
dev.off()
pdf(file="plots/ang_dens_diag.pdf",width=6,height=6)
#Setting plotting parameters
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
#Computing the empirical histogram for angular density
hist(polar_data$Q, freq = FALSE,xlab="Q",ylab=expression(f[Q](q)), main = "Angular density",sub="L1 coordinates",col=NULL,cex.lab=1.2, cex.axis=1.2,cex.main=1.5)
#Comparing estimated angular density function to empirical
lines(pred_Q,SPAR_angular_density,lwd=4,col=2)
dev.off()
pdf(file="plots/local_smooth.pdf",width=12,height=4)
#Setting plotting parameters
par(mfrow=c(1,3),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
#Comparing local and smooth estimates of threshold function
plot(pred_Q,SPAR_smooth_fit$pred_thresh,xlab="Q",ylab=expression(u[gamma]),main="Threshold",sub="L1 coordinates",typ="l",col=2,cex.lab=1.2, cex.axis=1.2,cex.main=1.5,lwd=4,ylim=range(SPAR_smooth_fit$pred_thresh,SPAR_local_fit$pred_thresh))
lines(pred_Q_loc,SPAR_local_fit$pred_thresh,lwd=4,col="red")
#Comparing local and smooth estimates of scale function
plot(pred_Q,SPAR_smooth_fit$pred_para$scale,xlab="Q",ylab=expression(sigma),main="Scale",sub="L1 coordinates",typ="l",col=3,cex.lab=1.2, cex.axis=1.2,cex.main=1.5,lwd=4,ylim=range(SPAR_smooth_fit$pred_para$scale,SPAR_local_fit$pred_para$scale))
lines(pred_Q_loc,SPAR_local_fit$pred_para$scale,lwd=4,col="green")
#Comparing local and smooth estimates of shape function
plot(pred_Q,SPAR_smooth_fit$pred_para$shape,xlab="Q",ylab=expression(xi),main="Shape",sub="L1 coordinates",typ="l",col=4,cex.lab=1.2, cex.axis=1.2,cex.main=1.5,lwd=4,ylim=range(SPAR_smooth_fit$pred_para$shape,SPAR_local_fit$pred_para$shape))
lines(pred_Q_loc,SPAR_local_fit$pred_para$shape,lwd=4,col="blue")
dev.off()
pdf(file="plots/ang_dens_diag.pdf",width=6,height=6)
#Setting plotting parameters
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
#Computing the empirical histogram for angular density
hist(polar_data$Q, freq = FALSE,xlab="Q",ylab=expression(f[Q](q)), main = "Angular density",sub="L1 coordinates",col=NULL,cex.lab=1.2, cex.axis=1.2,cex.main=1.5)
#Comparing estimated angular density function to empirical
lines(pred_Q,SPAR_angular_density,lwd=4,col="blue")
dev.off()
png(file="plots/simulated_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(data,SPAR_simulation$data_sample),xlim=range(data,SPAR_simulation$data_sample))
points(SPAR_simulation$data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
legend(range(data,L1_simulation$data_sample)[1],range(data,SPAR_simulation$data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
dev.off()
SPAR model simulations
#Plotting SPAR model simulations
png(file="plots/simulated_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(data,SPAR_simulation$data_sample),xlim=range(data,SPAR_simulation$data_sample))
points(SPAR_simulation$data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
legend(range(data,SPAR_simulation$data_sample)[1],range(data,SPAR_simulation$data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
dev.off()
SPAR_simulation$data_sample = apply(rbind(mus_data,sds_data,SPAR_simulation$data_sample),2,normalisation_inverse_function)
png(file="plots/simulated_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(data,SPAR_simulation$data_sample),xlim=range(data,SPAR_simulation$data_sample))
points(SPAR_simulation$data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
legend(range(data,SPAR_simulation$data_sample)[1],range(data,SPAR_simulation$data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
dev.off()
sum(SPAR_simulation$Q_sample>-2 & SPAR_simulation$Q_sample<-1)
sum(SPAR_simulation$Q_sample> -2 & SPAR_simulation$Q_sample< -1)
nsim
sum(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2)
sum(is.na(SPAR_simulation$data_sample))
which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2)
SPAR_simulation$R_sample[which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2) ]
u_vec = ifelse(Q_sample>=0,(1-Q_sample),(Q_sample+1))
v_vec = ifelse(Q_sample>=0, 1-abs(u_vec),-1+abs(u_vec))
Q_sample = SPAR_simulation$Q_sample
u_vec = ifelse(Q_sample>=0,(1-Q_sample),(Q_sample+1))
v_vec = ifelse(Q_sample>=0, 1-abs(u_vec),-1+abs(u_vec))
data_sample = cbind(R_sample*u_vec,R_sample*v_vec)
R_sample = SPAR_simulation$R_sample
u_vec = ifelse(Q_sample>=0,(1-Q_sample),(Q_sample+1))
v_vec = ifelse(Q_sample>=0, 1-abs(u_vec),-1+abs(u_vec))
data_sample = cbind(R_sample*u_vec,R_sample*v_vec)
data_sample[which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2) ,]
plot(data_sample[which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2) ,],pch=16,col=2)
png(file="plots/std_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(std_data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(std_data,data_sample),xlim=range(std_data,data_sample))
points(data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
legend(range(std_data,data_sample)[1],range(std_data,data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
dev.off()
png(file="plots/std_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(std_data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(std_data,data_sample),xlim=range(std_data,data_sample))
points(data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
points(data_sample[which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2) ,],pch=16,col=2)
legend(range(std_data,data_sample)[1],range(std_data,data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
dev.off()
source("master_functions.R")
thresh_prob = 0.7 #Non-exceedance probability.
k = 25 #Number of knots for threshold and scale spline models
k_shape = 8 #Number of knots for shape spline model
pred_Q = seq(-2,2,length.out=1001) #Angles at which to evaluate predicted quantities
pred_Q_loc = seq(-2,2,length.out=201) #Angles at which to evaluate predicted quantities for local fit
bw = 50 #Bandwdith parameter for the circular density estimation
num_neigh = 500 #Number of neighbours for local windown estimation
norm_choice = "L1" #Selecting the L1 norm. Can also choose L2 if desired/required
ret_period = 10 #return period for evaluating return level set
which.dataset = "A" #Select either A, B or C
data = readRDS(file=paste0("datafiles/dataset",which.dataset,".rds")) #loading in data from the datafiles folder
data = data[,2:1] #selecting only columns of interest - Tz and Hs
std_data = apply(data,2,function(x){(x-mean(x))/sd(x)}) #normalising the data
#computing standard deviations from each variable. Required for transforming back to the original scale
sds_data = apply(data,2,sd)
#computing means of each variable. Required for transforming back to the original scale
mus_data = apply(data,2,mean)
#Frequency of observation. We observe hourly observations 365 days per year
obs_year = 365*24
#Number of points to simulate from model
nsim = dim(data)[1]*(1-thresh_prob)
sample_data = std_data
if(!is.matrix(sample_data) | ncol(sample_data) != 2){
stop("sample_data must be an n x 2 matrix, where n denotes number of observations")
}
if(nsim < 1 | length(nsim) != 1){
stop("nsim must be a positive real integer")
}
if(!(norm_choice %in% c("L1","L2"))){
stop("norm_choice must equal either 'L1' or 'L2'")
}
if(thresh_prob >= 1 | thresh_prob <= 0 | length(thresh_prob) != 1){
stop("thresh_prob must be a single probability in (0,1)")
}
if(round(k) != k | k<=3){
stop("k must be a natural number greater that 3")
}
if(!is.null(k_shape)){
if(round(k_shape) != k_shape | k_shape<=3){
stop("If not set to NULL (i.e., constant shape), k_shape must be a natural number greater that 3")
}
}
if(min(pred_Q) < -2 | max(pred_Q)>2 | length(pred_Q)<=1){
stop("pred_Q should be a grid of angles in the interval [-2,2]")
}
if(bw < 0 | length(bw) != 1){
stop("bw must be a positive real number")
}
sgn = function(y){
if(y>=0){
return(1)
} else {
return(-1)
}
}
if(norm_choice == "L1"){
L1_rad = function(vec){
return(abs(vec[1])+abs(vec[2]))
}
L1_ang = function(vec){
return(sgn(vec[2])*(1-vec[1]))
}
#observed radial data
R = apply(sample_data,1,L1_rad)
#observed angular data
Q = apply( apply(sample_data,2,function(x,r){return(x/r)},r=R),1,L1_ang)
} else {
L2_rad = function(vec){
return(sqrt(vec[1]^2+vec[2]^2))
}
L2_ang = function(vec){
return(sgn(vec[2])*(2/pi)*acos(vec[1]))
}
#observed radial data
R = apply(sample_data,1,L2_rad)
#observed angular data
Q = apply( apply(sample_data,2,function(x,r){return(x/r)},r=R),1,L2_ang)
}
#dataframe of angular-radial data
polar_data = data.frame(R=R,Q=Q)
#transform radial component to the log scale. This guarantees positivity in the resulting threshold function
polar_data$logR = log(polar_data$R)
#Formulation for threshold function. s(Q, bs='cc',k=k) is a cyclic cubic spline over Q with basis dimension k
fmla_ald = paste0("logR ~ s(Q, bs='cc',k=",k,")")
#Fit asymmetric Laplace distribution to estimate threshold function using evgam
m_ald = evgam(as.formula(fmla_ald), data=polar_data, family="ald", ald.args=list(tau=thresh_prob))
#Estimated threshold functions. The exp function is used to transform back to R from the logR scale
gpd_thresh_function = exp(predict(m_ald, newdata=polar_data)$location)
#all exceedances of threshold function
gpd_thresh_exceedances = polar_data$R - gpd_thresh_function
#checking which exceedances are positive
positive_exceedances_indicator = which(gpd_thresh_exceedances>0)
#extracting positive exceedances
gpd_thresh_exceedances = gpd_thresh_exceedances[positive_exceedances_indicator]
#dataframe of threshold exceedance data. We only save exceedances - we don't need the rest of the radial data
polar_exceedance_data = data.frame(Q=polar_data$Q[positive_exceedances_indicator],R_exc=gpd_thresh_exceedances)
#Checking if the shape is assumed to be constant
if(is.null(k_shape)){
#formulation for scale function
spl=paste0("R_exc ~ s(Q, bs='cc',k=",k,")")
#formulation for both scale and shape. ~1 specifies a constant shape
fmla_gpd = list(as.formula(spl), ~1)
#fit non-stationary GPD model using evgam
m_gpd = evgam(fmla_gpd, data=polar_exceedance_data, family="gpd")
} else {
#define second angular component that is identical as first. This is so that we can define separate splines for the shape and scale
polar_exceedance_data$Q2 = polar_exceedance_data$Q
#formulation for both scale and shape. Note that k and k_shape are unlikely to be the same
fmla_gpd = list(as.formula(paste0("R_exc ~ s(Q, bs='cc',k=",k,")")), as.formula(paste0("R_exc ~ s(Q2, bs='cc',k=",k_shape,")")))
#fit non-stationary GPD model using evgam
m_gpd = evgam(fmla_gpd, data=polar_exceedance_data, family="gpd")
}
#we transform the angular component to be within the interval [0,2pi). This is because the density.circular function is defined only for standard polar angles
scale_Q = (Q+2)*pi/2
#estimating the density function using the `circular' R package with a von Mises kernel
dens_est = density.circular(as.circular(scale_Q,type="angles",units="radians",template="none",modulo="2pi",zero=0,rotation="counter"), bw=bw,kernel="vonmises")
#Making sure we equal 2pi at the endpoint
dens_est$x[length(dens_est$x)] = 2*pi
#obtaining the estimated density function on the original angular scale. (pi/2) represents the corresponding Jacobian
f_Q = approxfun(x = (2*dens_est$x)/pi - 2,y = (pi/2)*dens_est$y)
kd_integral = function(u,x,f_Q){
if(x>0.99999){
return(1 - u) #numerical error for really large probabilities. This ensures we integrate to 1
} else {
return(integrate(f_Q,-2,x)$value - u)
}
}
kd_root = function(u,f_Q){
return(uniroot(f=kd_integral,interval = c(-2,2),u=u,f_Q = f_Q)$root)
}
unif_sample = runif(nsim)
Q_sample = sapply(unif_sample,kd_root,f_Q=f_Q)
ind = which(Q_sample >1 & Q_sample <2)
ind
unif_sample[ind]
integrate(f_Q,-2,2)$value
kd_integral = function(u,x,f_Q){
if(u>0.99999){
return(integrate(f_Q,-2,x)$value - integrate(f_Q,-2,2)$value) #numerical error for really large probabilities. This ensures we integrate to 1
} else {
return(integrate(f_Q,-2,x)$value - u)
}
}
kd_root = function(u,f_Q){
return(uniroot(f=kd_integral,interval = c(-2,2),u=u,f_Q = f_Q)$root)
}
unif_sample = runif(nsim)
Q_sample = sapply(unif_sample,kd_root,f_Q=f_Q)
#obtain threshold function estimates for sample angles
thresh_sample = exp(predict(m_ald, newdata=data.frame(Q=Q_sample))$location)
if(is.null(k_shape)){
#obtain GPD parameter function estimates for sample angles
para_sample = predict(m_gpd, newdata=data.frame(Q=Q_sample),type="response")
} else {
#obtain GPD parameter function estimates for sample angles
para_sample = predict(m_gpd,type = "response",newdata=data.frame(Q=Q_sample,Q2=Q_sample))
}
unif_sample = runif(nsim)
R_sample = thresh_sample + (para_sample$scale/para_sample$shape)*(unif_sample^(-para_sample$shape)-1)
#We check which coordinate system we are working in
if(norm_choice == "L1"){
#Defining points on the unit sphere for the L1 norm
u_vec = ifelse(Q_sample>=0,(1-Q_sample),(Q_sample+1))
v_vec = ifelse(Q_sample>=0, 1-abs(u_vec),-1+abs(u_vec))
} else {
#Defining points on the unit sphere for the L2 norm
u_vec = ifelse(Q_sample>=0,cos(pi*Q_sample/2),cos(-pi*Q_sample/2))
v_vec = ifelse(Q_sample>=0, sqrt(1-u_vec^2),-sqrt(1-u_vec^2))
}
data_sample = cbind(R_sample*u_vec,R_sample*v_vec)
png(file="plots/std_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(std_data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(std_data,data_sample),xlim=range(std_data,data_sample))
points(data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
points(data_sample[which(SPAR_simulation$Q_sample> 1 & SPAR_simulation$Q_sample< 2) ,],pch=16,col=2)
dev.off()
source("master_functions.R")
thresh_prob = 0.7 #Non-exceedance probability.
k = 25 #Number of knots for threshold and scale spline models
k_shape = 8 #Number of knots for shape spline model
pred_Q = seq(-2,2,length.out=1001) #Angles at which to evaluate predicted quantities
pred_Q_loc = seq(-2,2,length.out=201) #Angles at which to evaluate predicted quantities for local fit
bw = 50 #Bandwdith parameter for the circular density estimation
num_neigh = 500 #Number of neighbours for local windown estimation
norm_choice = "L1" #Selecting the L1 norm. Can also choose L2 if desired/required
ret_period = 10 #return period for evaluating return level set
# Data -----------------------------------------
which.dataset = "A" #Select either A, B or C
data = readRDS(file=paste0("datafiles/dataset",which.dataset,".rds")) #loading in data from the datafiles folder
data = data[,2:1] #selecting only columns of interest - Tz and Hs
std_data = apply(data,2,function(x){(x-mean(x))/sd(x)}) #normalising the data
#this standardising ensures the mean will be at (0,0), as required for the SPAR model
#computing standard deviations from each variable. Required for transforming back to the original scale
sds_data = apply(data,2,sd)
#computing means of each variable. Required for transforming back to the original scale
mus_data = apply(data,2,mean)
#Frequency of observation. We observe hourly observations 365 days per year
obs_year = 365*24
#Number of points to simulate from model
nsim = dim(data)[1]*(1-thresh_prob)
# Fitting SPAR model ------------------------------------------------------------
#We fit the SPAR model smoothly with L1 coordinates
SPAR_smooth_fit = SPAR_smooth(sample_data = std_data,norm_choice = norm_choice,thresh_prob = thresh_prob,k=k,k_shape = k_shape,pred_Q = pred_Q)
#We fit the SPAR model locally (via local windows) with L1 coordinates
SPAR_local_fit = SPAR_local(sample_data = std_data,norm_choice = norm_choice,thresh_prob = thresh_prob,pred_Q = pred_Q_loc,num_neigh = num_neigh)
#We estimate the angular density with L1 coordinates
SPAR_angular_density = SPAR_angular_density(sample_data = std_data,norm_choice = norm_choice,pred_Q = pred_Q,bw = bw)
#Define density levels for which to evaluate equidensity contours
density_levels = 10^(-c(3,6))
#Adjusting density levels to account for Jacobian of standardisation
density_levels = density_levels*prod(sds_data)
#Estimate equidensity contours for the desired levels
SPAR_equidensity_curves = SPAR_equidensity_contours(density_levels = density_levels,norm_choice=norm_choice,SPAR_GPD=SPAR_smooth_fit,SPAR_ang=SPAR_angular_density)
#Estimate return level set for desired return period
SPAR_RL_set = SPAR_ret_level_sets(ret_period = ret_period,obs_year = obs_year,norm_choice = norm_choice,SPAR_GPD = SPAR_smooth_fit)
#Simulate new data from fitted SPAR model
SPAR_simulation = SPAR_simulation(sample_data=std_data,nsim=nsim,norm_choice = norm_choice,thresh_prob = thresh_prob,k=k,k_shape = k_shape,pred_Q = pred_Q,bw=bw)
# Validating model fits ---------------------------------------------------
#Obtaining polar coordinates of dataset, along with points on the norm unit circle
if(norm_choice == "L1"){
L1_rad = function(vec){
return(abs(vec[1])+abs(vec[2]))
}
L1_ang = function(vec){
return(sgn(vec[2])*(1-vec[1]))
}
#observed radial data
R = apply(std_data,1,L1_rad)
#observed angular data
Q = apply( apply(std_data,2,function(x,r){return(x/r)},r=R),1,L1_ang)
#dataframe of angular-radial data
polar_data = data.frame(R=R,Q=Q)
#Defining points on the unit sphere for the L1 norm
u_vec = ifelse(pred_Q>=0,(1-pred_Q),(pred_Q+1))
v_vec = ifelse(pred_Q>=0, 1-abs(u_vec),-1+abs(u_vec))
} else {
L2_rad = function(vec){
return(sqrt(vec[1]^2+vec[2]^2))
}
L2_ang = function(vec){
return(sgn(vec[2])*(2/pi)*acos(vec[1]))
}
#observed radial data
R = apply(std_data,1,L2_rad)
#observed angular data
Q = apply( apply(std_data,2,function(x,r){return(x/r)},r=R),1,L2_ang)
#dataframe of angular-radial data
polar_data = data.frame(R=R,Q=Q)
#Defining points on the unit sphere for the L2 norm
u_vec = ifelse(pred_Q>=0,cos(pi*pred_Q/2),cos(-pi*pred_Q/2))
v_vec = ifelse(pred_Q>=0, sqrt(1-u_vec^2),-sqrt(1-u_vec^2))
}
#We transform everything from the normalised data back to the original coordinates
#This function is a wrapper for performing this transformation
normalisation_inverse_function = function(y){
mu = y[1]
sd = y[2]
norm_data = y[3:length(y)]
return(norm_data*sd + mu)
}
#Transforming density contours back to original coordinates
for(i in 1:length(SPAR_equidensity_curves)){
SPAR_equidensity_curves[[i]] = apply(rbind(mus_data,sds_data,SPAR_equidensity_curves[[i]]),2,normalisation_inverse_function)
}
SPAR_RL_set = apply(rbind(mus_data,sds_data,SPAR_RL_set),2,normalisation_inverse_function)
SPAR_simulation$data_sample = apply(rbind(mus_data,sds_data,SPAR_simulation$data_sample),2,normalisation_inverse_function)
#Plotting SPAR model simulations
png(file="plots/simulated_data.png",width=600,height=600)
par(mfrow=c(1,1),mgp=c(2.5,1,0),mar=c(5,4,4,2)+0.1)
plot(data,pch=16,col="grey",main="SPAR simulations",sub="L1 coordinates",xlab="Tz",ylab="Hs",cex.lab=1.2, cex.axis=1.2,cex.main=1.5,ylim=range(data,SPAR_simulation$data_sample),xlim=range(data,SPAR_simulation$data_sample))
points(SPAR_simulation$data_sample,pch=16,col=adjustcolor(3,alpha.f = 0.2))
legend(range(data,SPAR_simulation$data_sample)[1],range(data,SPAR_simulation$data_sample)[2],legend=c("Observerd","Simulated"),pch=16,col=c("grey",adjustcolor(3,alpha.f = 0.2)),cex=1.2,bg="white")
#issue with angles in 1 to 2
dev.off()
